{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# from gensim.test.utils import datapath, get_tmpfile\n",
    "# from gensim.models import KeyedVectors\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeds = KeyedVectors.load_word2vec_format('word_vectors.txt')\n",
    "# print(\"Initialized Word Embeddings...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorize(sentence):\n",
    "#     unk = word_embeds.wv['unknown']\n",
    "#     matrix = []\n",
    "#     tokens = nltk.word_tokenize(sentence)\n",
    "#     tokens = [i.lower() for i in tokens]\n",
    "#     for i in tokens:\n",
    "#         if i not in word_embeds.vocab:\n",
    "#             matrix.append(unk)\n",
    "#         else:\n",
    "#             matrix.append(word_embeds.wv[i])            \n",
    "#     matrix = pad_sequences(maxlen=18, sequences=np.array([matrix]), padding=\"post\", value=unk,dtype='float32')\n",
    "#     return matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Query</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the price for the event?</td>\n",
       "      <td>get_event_fees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Due to unavoidable reasons I'm unable to atten...</td>\n",
       "      <td>is_refundable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>When is the deadline to make the payment?</td>\n",
       "      <td>get_registration_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>How much does it cost to register for the event?</td>\n",
       "      <td>get_event_fees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Do you have any online payment options for the...</td>\n",
       "      <td>get_payment_method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
       "0           0             0               0   \n",
       "1           1             1               1   \n",
       "2           2             2               2   \n",
       "3           3             3               3   \n",
       "4           4             4               4   \n",
       "\n",
       "                                               Query                 Action  \n",
       "0                   What is the price for the event?         get_event_fees  \n",
       "1  Due to unavoidable reasons I'm unable to atten...          is_refundable  \n",
       "2          When is the deadline to make the payment?  get_registration_date  \n",
       "3   How much does it cost to register for the event?         get_event_fees  \n",
       "4  Do you have any online payment options for the...     get_payment_method  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for index,row in data.iterrows():\n",
    "    tokens = nltk.word_tokenize(row['Query'])\n",
    "    for i in tokens:\n",
    "        if not i in vocab:\n",
    "            vocab.append(i)\n",
    "vocab.append('UNK')\n",
    "vocab.append('PAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 391\n"
     ]
    }
   ],
   "source": [
    "n_words = len(vocab)\n",
    "print(\"Number of unique tokens: \" + str(n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = list(data['Action'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get_event_fees', 'is_refundable', 'get_registration_date', 'get_payment_method', 'get_prizes', 'get_discounts', 'greet', 'show_schedule', 'get_event_date', 'get_event_time', 'show_accomodation', 'show_speakers', 'speaker_details_extra', 'show_food_arrangements', 'get_distance', 'get_location', 'show_contact_info', 'about_chatbot']\n",
      "Number of unique actions : 18\n"
     ]
    }
   ],
   "source": [
    "print(actions)\n",
    "n_actions = len(actions)\n",
    "print(\"Number of unique actions : \" + str(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 291 entries, 0 to 290\n",
      "Data columns (total 5 columns):\n",
      "Unnamed: 0        291 non-null int64\n",
      "Unnamed: 0.1      291 non-null int64\n",
      "Unnamed: 0.1.1    291 non-null int64\n",
      "Query             291 non-null object\n",
      "Action            291 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_index_1 = {}\n",
    "action_index_2 = {}\n",
    "\n",
    "for i,v in enumerate(actions):\n",
    "    action_index_1[i] = v\n",
    "    action_index_2[v] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_matrix(sentence):\n",
    "    matrix = []\n",
    "    w = nltk.word_tokenize(sentence)\n",
    "    for i in w:\n",
    "        if i in vocab:\n",
    "            matrix.append(vocab.index(i))\n",
    "        else :\n",
    "            matrix.append(vocab.index('UNK'))\n",
    "    x = pad_sequences(maxlen=18, sequences=[matrix], padding=\"post\", value=vocab.index('PAD'))\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_array(action):\n",
    "    \n",
    "    z = np.zeros(n_actions)\n",
    "    z[action_index_2[action]] = 1\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(get_categorical_array('is_refundable'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for index,row in data.iterrows():\n",
    "    \n",
    "    X.append(get_index_matrix(row['Query']))\n",
    "    Y.append(get_categorical_array(row['Action']))\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 18)\n",
      "(291, 18)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 18) (276, 18)\n",
      "(15, 18) (15, 18)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to load the model if you don't wish to train\n",
    "# Make sure you comment out the training part if you are uncommenting this block\n",
    "\n",
    "# json_file = open('Model/model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# model.load_weights(\"Model/model.h5\")\n",
    "# print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words,output_dim=15,input_length=18))\n",
    "model.add(Bidirectional(LSTM(units=20)))\n",
    "model.add(Dense(n_actions,activation='softmax'))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 15)            5865      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40)                5760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                738       \n",
      "=================================================================\n",
      "Total params: 12,363\n",
      "Trainable params: 12,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "291/291 [==============================] - 6s 21ms/step - loss: 0.3106 - acc: 0.9485\n",
      "Epoch 2/15\n",
      "291/291 [==============================] - 6s 21ms/step - loss: 0.2752 - acc: 0.9519\n",
      "Epoch 3/15\n",
      "291/291 [==============================] - 7s 25ms/step - loss: 0.2439 - acc: 0.9588\n",
      "Epoch 4/15\n",
      "291/291 [==============================] - 7s 23ms/step - loss: 0.2159 - acc: 0.9622\n",
      "Epoch 5/15\n",
      "291/291 [==============================] - 6s 21ms/step - loss: 0.1830 - acc: 0.9691\n",
      "Epoch 6/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.2148 - acc: 0.9622\n",
      "Epoch 7/15\n",
      "291/291 [==============================] - 6s 22ms/step - loss: 0.1544 - acc: 0.9759\n",
      "Epoch 8/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.1321 - acc: 0.9759\n",
      "Epoch 9/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.1264 - acc: 0.9725\n",
      "Epoch 10/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.0993 - acc: 0.9863\n",
      "Epoch 11/15\n",
      "291/291 [==============================] - 6s 21ms/step - loss: 0.0929 - acc: 0.9828\n",
      "Epoch 12/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.0899 - acc: 0.9863\n",
      "Epoch 13/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.0727 - acc: 0.9828\n",
      "Epoch 14/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.0662 - acc: 0.9897\n",
      "Epoch 15/15\n",
      "291/291 [==============================] - 6s 20ms/step - loss: 0.0587 - acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f701b1b72b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,batch_size=2,epochs=15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "score: 0.06\n",
      "acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(x_test,y_test, verbose = 1, batch_size = 2)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Model/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
